{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOBTgRIrQxWV3HHLMEECKwT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Implementation of stacking , with max voting as classification model\n"],"metadata":{"id":"ZWHGdlLy3vWc"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jvnZwvsM3sRh","executionInfo":{"status":"ok","timestamp":1676946457253,"user_tz":-330,"elapsed":10,"user":{"displayName":"CE137_Om_Soni","userId":"00290265016344326683"}},"outputId":"d1dee12f-86cd-4f20-ed7f-148ad043918f"},"outputs":[{"output_type":"stream","name":"stdout","text":["[1 1 1 1 1 0 0]\n","accuracy :  0.7142857142857143\n","[[1 1]\n"," [1 4]]\n"]}],"source":["# 20 minutes\n","from sklearn import preprocessing\n","from sklearn.naive_bayes import GaussianNB, MultinomialNB,CategoricalNB\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score \n","from sklearn.metrics import confusion_matrix  \n","\n","def max_voting(output):\n","  votes={}\n","  for elem in output:\n","    if elem in votes:\n","      votes[elem]+=1\n","    else :\n","      votes[elem]=1\n","  \n","  final_output=-1\n","  max_votes=-1\n","  for elem in votes:\n","    if max_votes<votes[elem]:\n","      max_votes=votes[elem]\n","      final_output=elem\n","      pass\n","    pass\n","  print(votes)\n","  return final_output,max_votes\n","  pass\n","\n","def get_data_set():\n","  weather = ['Sunny', 'Sunny', 'Overcast', 'Rainy', 'Rainy','Rainy', 'Overcast','Sunny', 'Sunny', 'Rainy', 'Sunny', 'Overcast', 'Overcast', 'Rainy']\n","  temp = ['Hot','Hot','Hot','Mild','Cool','Cool','Cool','Mild','Cool','Mild','Mild','Mild','Hot','Mild']\n","  play=['No','No','Yes','Yes','Yes','No','Yes','No','Yes','Yes','Yes','Yes','Yes','No']\n","  le=preprocessing.LabelEncoder()\n","  weather_encoded=le.fit_transform(weather)\n","  temp_encoded=le.fit_transform(temp)\n","  play_encoded=le.fit_transform(play)\n","  features=tuple(zip(weather_encoded,temp_encoded))\n","  return features,play_encoded\n","  pass\n","\n","def get_individual_classifiers(x_train,y_train,no_of_models=10):\n","  individual_classifiers=[]\n","  for _ in range(no_of_models):\n","    \n","    new_model=CategoricalNB(alpha=1)\n","    new_model.fit(x_train,y_train)\n","    individual_classifiers.append(new_model)\n","    pass\n","  return individual_classifiers\n","  pass\n","\n","def individual_predict(individual_classifiers,input):\n","  output=[]\n","  for classifier in individual_classifiers:\n","    curr_output=list(classifier.predict(input))\n","    output=output+curr_output\n","    pass\n","  return output\n","  pass\n","\n","def get_meta_classifier(x,y):\n","  individual_classifiers=get_individual_classifiers(x_train,y_train)\n","  output=individual_predict(individual_classifiers,x)\n","  meta_x=output\n","  meta_y=[]\n","  div=len(meta_x)//len(x)\n","  for _ in range(div):\n","    meta_y=meta_y+list(y)\n","  meta_classifier=LogisticRegression(random_state=0).fit(x, y)\n","  return meta_classifier\n","  pass\n","\n","def get_accuracy(y_pred,y_test):\n","  \n","  return accuracy_score(y_pred,y_test)\n","  pass\n","\n","\n","x,y=get_data_set()\n","x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=137,test_size=0.50)\n","meta_classifier=get_meta_classifier(x_train,y_train)\n","\n","y_pred=meta_classifier.predict(x_test)\n","print(y_pred)\n","print(\"accuracy : \",get_accuracy(y_pred,y_test))\n","print(confusion_matrix(y_test,y_pred))\n","# x_1,y_1=individual_predict(individual_classifiers,[[1,2]])\n","# print(x_1,y_1)\n","\n"]},{"cell_type":"code","source":["from sklearn.datasets import load_diabetes\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import AdaBoostRegressor\n","from sklearn.metrics import mean_squared_error\n","\n","X, y = load_diabetes(return_X_y=True)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n","\n","model = AdaBoostRegressor(n_estimators=100, random_state=42)\n","model.fit(X_train, y_train)\n","\n","y_pred = model.predict(X_test)\n","mse = mean_squared_error(y_test, y_pred)\n","print('MSE: ', mse)\n"],"metadata":{"id":"r6V0q5C_2MGO","executionInfo":{"status":"ok","timestamp":1676947279746,"user_tz":-330,"elapsed":568,"user":{"displayName":"CE137_Om_Soni","userId":"00290265016344326683"}},"outputId":"4654bae1-26f9-4999-a63b-3eac9e2ee9b3","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["MSE:  2983.591342966658\n"]}]},{"cell_type":"markdown","source":["# stacking using regression and low diabetes database"],"metadata":{"id":"t1onSksYHdjk"}},{"cell_type":"code","source":["# 20 minutes\n","from sklearn import preprocessing\n","from sklearn.naive_bayes import GaussianNB, MultinomialNB,CategoricalNB\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score   \n","from sklearn.datasets import load_diabetes\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import confusion_matrix\n","\n","# def max_voting(output):\n","#   votes={}\n","#   for elem in output:\n","#     if elem in votes:\n","#       votes[elem]+=1\n","#     else :\n","#       votes[elem]=1\n","  \n","#   final_output=-1\n","#   max_votes=-1\n","#   for elem in votes:\n","#     if max_votes<votes[elem]:\n","#       max_votes=votes[elem]\n","#       final_output=elem\n","#       pass\n","#     pass\n","#   print(votes)\n","#   return final_output,max_votes\n","#   pass\n","\n","def get_data_set():\n","  import pandas as pd\n","  dataset=load_diabetes()\n","  x=dataset.data\n","  y=dataset.target\n","  return x,y\n","  pass\n","\n","def get_individual_classifiers(x_train,y_train,no_of_models=10):\n","  individual_classifiers=[]\n","  for _ in range(no_of_models):\n","    new_model=LinearRegression()\n","    new_model.fit(x_train,y_train)\n","    individual_classifiers.append(new_model)\n","    pass\n","  return individual_classifiers\n","  pass\n","\n","def individual_predict(individual_classifiers,input):\n","  output=[]\n","  for classifier in individual_classifiers:\n","    curr_output=list(classifier.predict(input))\n","    output=output+curr_output\n","    pass\n","  return output\n","  pass\n","\n","def get_meta_classifier(x,y):\n","  individual_classifiers=get_individual_classifiers(x_train,y_train)\n","  output=individual_predict(individual_classifiers,x)\n","  meta_x=output\n","  meta_y=[]\n","  div=len(meta_x)//len(x)\n","  for _ in range(div):\n","    meta_y=meta_y+list(y)\n","  meta_classifier=LinearRegression().fit(x, y)\n","  return meta_classifier\n","  pass\n","\n","def get_accuracy(y_pred,y_test):\n","  return accuracy_score(y_pred,y_test)\n","  pass\n","\n","def get_mse(y_pred,y_test):\n","  return mean_squared_error(y_pred,y_test)\n","  pass\n","\n","x,y=get_data_set()\n","# print(x,y)\n","x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=137,test_size=0.50)\n","meta_classifier=get_meta_classifier(x_train,y_train)\n","y_pred=meta_classifier.predict(x_test)\n","print(\"mse loss : \",get_mse(y_pred,y_test))\n","\n","# x_1,y_1=individual_predict(individual_classifiers,[[1,2]])\n","# print(x_1,y_1)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":399},"id":"P5TVM7Q5Hg-V","executionInfo":{"status":"error","timestamp":1676946658292,"user_tz":-330,"elapsed":2146,"user":{"displayName":"CE137_Om_Soni","userId":"00290265016344326683"}},"outputId":"739012f2-85ea-4fe5-f8e8-bbf12bacc226"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["mse loss :  2679.3209640213354\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-c5eb8b5efcfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mse loss : \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_mse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;31m# x_1,y_1=individual_predict(individual_classifiers,[[1,2]])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;31m# print(x_1,y_1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \"\"\"\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m     95\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"]}]},{"cell_type":"markdown","source":["# Adaboost classifier"],"metadata":{"id":"A34pWSkl8BXs"}},{"cell_type":"code","source":["from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score   \n","from sklearn.datasets import load_breast_cancer\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.metrics import confusion_matrix\n","\n","def get_data_set():\n","  import pandas as pd\n","  dataset=load_breast_cancer()\n","  x=dataset.data\n","  y=dataset.target\n","  return x,y\n","  pass\n","\n","def get_classifier(x,y):\n","  return AdaBoostClassifier().fit(x,y)\n","\n","def get_accuracy(y_pred,y_test):\n","  return accuracy_score(y_pred,y_test)\n","  pass\n","\n","def print_classification_report(y_pred,y_test):\n","  print(\"confusion matrix of addboostclassification\")\n","  cmat=confusion_matrix(y_test,y_pred)\n","  print(cmat)\n","  pass\n","x,y=get_data_set()\n","# print(x,y)\n","x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=137,test_size=0.50)\n","classifier=get_classifier(x_train,y_train)\n","y_pred=classifier.predict(x_test)\n","print(\"accuracy : \",get_accuracy(y_pred,y_test))\n","print_classification_report(y_test,y_pred)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-M1xJhAhL1g6","executionInfo":{"status":"ok","timestamp":1675158442107,"user_tz":-330,"elapsed":689,"user":{"displayName":"CE137_Om_Soni","userId":"00290265016344326683"}},"outputId":"92823a0c-3a7f-420e-ba55-72f1989ab431"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy :  0.9789473684210527\n","confusion matrix of addboostclassification\n","[[103   2]\n"," [  4 176]]\n"]}]},{"cell_type":"markdown","source":["# Use StackingClassifier from sklearn to implement the same on cancer dataset. \n","Bagging and RandomForest"],"metadata":{"id":"WqBBSmVsOefs"}},{"cell_type":"code","source":["from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score   \n","from sklearn.datasets import load_breast_cancer\n","from sklearn.metrics import confusion_matrix\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import BaggingClassifier\n","\n","def get_data_set():\n","  import pandas as pd\n","  dataset=load_breast_cancer()\n","  x=dataset.data\n","  y=dataset.target\n","  return x,y\n","  pass\n","\n","def get_classifier(x,y):\n","  return BaggingClassifier().fit(x,y)\n","\n","def get_accuracy(y_pred,y_test):\n","  return accuracy_score(y_pred,y_test)\n","  pass\n","\n","def print_classification_report(y_pred,y_test):\n","  print(\"confusion matrix of bagging on descision tree classifier : \")\n","  cmat=confusion_matrix(y_test,y_pred)\n","  print(cmat)\n","  pass\n","\n","x,y=get_data_set()\n","# print(x,y)\n","x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=137,test_size=0.50)\n","classifier=get_classifier(x_train,y_train)\n","y_pred=classifier.predict(x_test)\n","print(\"accuracy : \",get_accuracy(y_pred,y_test))\n","print_classification_report(y_test,y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NLk_eGPJOiHH","executionInfo":{"status":"ok","timestamp":1675159070985,"user_tz":-330,"elapsed":403,"user":{"displayName":"CE137_Om_Soni","userId":"00290265016344326683"}},"outputId":"6766acf4-2afc-44ef-d99a-4b4bfaf0c9bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy :  0.9438596491228071\n","confusion matrix of bagging on descision tree classifier : \n","[[100   9]\n"," [  7 169]]\n"]}]},{"cell_type":"markdown","source":["# Exercise : Try Adaboost Regression on concrete_data.csv."],"metadata":{"id":"EkXHPxOoQxu1"}}]}